# Analytical tools & Interpretability
- [On the Biology of a Large Language Model](https://www.jiqizhixin.com/articles/2025-03-28-10)
- [Efficiently Serving LLM Reasoning Programs with Certaindex](https://arxiv.org/abs/2412.20993)
- [Finding Transformer Circuits with Edge Pruning](https://arxiv.org/abs/2406.16778)


# LLMs Spurious Correlation & Solutions 
- [How Likely Do LLMs with CoT Mimic Human Reasoning?](https://arxiv.org/pdf/2402.16048)
- [DIRECT PREFERENCE OPTIMIZATION USING SPARSE FEATURE-LEVEL CONSTRAINTS](https://arxiv.org/pdf/2411.07618?)
- [LOCKING DOWN THE FINETUNED LLMS SAFETY](https://arxiv.org/pdf/2410.10343)
- [Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future](https://aclanthology.org/2023.emnlp-main.276.pdf)
- [Semformer: Transformer Language Models with Semantic Planning](https://arxiv.org/pdf/2409.11143)
- [GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective](https://arxiv.org/pdf/2211.08073)


# Reward Hacking 
- [详解 Reward Hacking](https://zhuanlan.zhihu.com/p/21488802591)
- [理解RLHF中的Reward Hacking](https://zhuanlan.zhihu.com/p/6082362466)
- [Reward Hacking in Reinforcement Learning](https://lilianweng.github.io/posts/2024-11-28-reward-hacking/#:~:text=Reward%20hacking%20occurs%20when%20a%20reinforcement%20learning%20%28RL%29,without%20genuinely%20learning%20or%20completing%20the%20intended%20task.)
- [Defining and Characterizing Reward Hacking](https://arxiv.org/pdf/2209.13085)
- [Reward Shaping to Mitigate Reward Hacking in RLHF](https://arxiv.org/pdf/2502.18770)
- [Adversarial Training of Reward Models](https://arxiv.org/pdf/2504.06141)

