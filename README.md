#### Deep Neural Networks
- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)
- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
- [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

#### Self-Supervised Learning
- [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748)
- [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)
- [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230)
- [Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733)
- [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722)
- [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)
- [Contrastive Multiview Coding](https://arxiv.org/abs/1906.05849)
- [Exploring Simple Siamese Representation Learning](https://arxiv.org/abs/2011.10566)
- [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882)
- [VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning](https://arxiv.org/abs/2105.04906)


#### Dataset Distillation
- [Dataset Distillation by Matching Training Trajectories](https://arxiv.org/abs/2203.11932)
- [Accelerating Dataset Distillation via Model Augmentation](https://arxiv.org/abs/2212.06152)
- [Dataset Condensation with Distribution Matching](https://arxiv.org/abs/2110.04181)
- [Dataset Distillation via the Wasserstein Metric](https://arxiv.org/abs/2311.18531)
- [Dataset Meta-Learning from Kernel Ridge-Regression](https://arxiv.org/abs/2011.00050)
- [Dataset Distillation using Neural Feature Regression](https://arxiv.org/abs/2206.00719)
- [Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective](https://arxiv.org/abs/2306.13092)
- [On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm](https://arxiv.org/abs/2312.03526)


#### Generative Models
- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)
- [beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework](https://openreview.net/forum?id=Sy2fzU9gl)
- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)
- [Wasserstein GAN](https://arxiv.org/abs/1701.07875)
- [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)
- [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)